{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8754136e",
   "metadata": {},
   "source": [
    "# Word frequency differences between two text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f314d85",
   "metadata": {},
   "source": [
    "You have two books (or other writings). Which words are overrepresented in book *A*, and which are overrepresented in *B*? One way to see is Dunning log likelihood.\n",
    "\n",
    "See: Dunning, T. Accurate Methods for the Statistics of Surprise and Coincidence. *Computational Linguistics* 19, 61–74 (1993).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9a9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import chi2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92f777",
   "metadata": {},
   "source": [
    "## Do the actual load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb64cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = \"\"\n",
    "with open('exp_black_y.csv') as fh:\n",
    "    for line in fh:\n",
    "        pc += line\n",
    "\n",
    "sc = \"\"\n",
    "with open('exp_black_n.csv') as fh:\n",
    "    for line in fh:\n",
    "        sc += line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec0d01",
   "metadata": {},
   "source": [
    "## Change certain punctuation to spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "410c7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = \"“”,.?\\\";:-_—!\"  # fixme - add slash\n",
    "SPACES = ' ' * len(PUNCT)\n",
    "table = str.maketrans(PUNCT, SPACES)\n",
    "\n",
    "ps = pc.translate(table).lower().split()\n",
    "ss = sc.translate(table).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18053274",
   "metadata": {},
   "source": [
    "## Define stop words and filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9099a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = \"a able about across after all almost also am among an and any are as at be because been but by can cannot could dear did do does either else ever every for from get got had has have he her hers him his how however i if in into is it its just least let like likely may me might most must my neither no nor not of off often on only or other our own rather said say says she should since so some than that the their them then there these they this tis to too twas us wants was we were what when where which while who whom why will with would yet you your\"\n",
    "# https://www.textfixer.com/tutorials/common-english-words.txt\n",
    "swl = stopwords.split() + ['chapter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "372a91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all(tlist, slist):\n",
    "    for w in tqdm(slist):\n",
    "        tlist = list(filter(lambda a: a != w, tlist))\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fbac16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:10<00:00,  1.70it/s]\n",
      "  9%|▉         | 11/120 [00:06<01:08,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bfc2f36ef3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# takes a while\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-aa75e7483393>\u001b[0m in \u001b[0;36mfilter_all\u001b[0;34m(tlist, slist)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfilter_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-aa75e7483393>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfilter_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pf = filter_all(ps, swl)\n",
    "sf = filter_all(ss, swl)\n",
    "# Takes about 1 min per 20 MB CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1c5e4",
   "metadata": {},
   "source": [
    "## Demo of filtered text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae11bac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patient/famili',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'regard',\n",
       " 'diagnosi',\n",
       " 'plan',\n",
       " 'care',\n",
       " 'subjective',\n",
       " 'chart',\n",
       " 'reviewed']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf[119:129]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3795c7d",
   "metadata": {},
   "source": [
    "## Count up words in each corpus (longest step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1e6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wlist2freqs(wlist):\n",
    "    multiplier = 1000000\n",
    "    denom = len(wlist)\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in vocab:\n",
    "        n = wlist.count(w)\n",
    "        fdict[w] = n / denom * multiplier\n",
    "    return(fdict)\n",
    "\n",
    "def wlist2counts(wlist):\n",
    "    \"\"\"Given a text (list of words), return dict where keys are words and values are word counts.\"\"\"\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in tqdm(vocab):\n",
    "        fdict[w] = wlist.count(w)\n",
    "    return(fdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e59bcb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 509/49151 [00:40<1:03:57, 12.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-15b48e996afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pd = wlist2freqs(pf)  # 6 sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sd = wlist2freqs(sf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlist2counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-34655eeae8ae>\u001b[0m in \u001b[0;36mwlist2counts\u001b[0;34m(wlist)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pd = wlist2freqs(pf)  # 6 sec\n",
    "# sd = wlist2freqs(sf)\n",
    "pcount = wlist2counts(pf)\n",
    "\n",
    "# Estimate 1 hour for just one corpus. Too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea90dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scount = wlist2counts(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ac79",
   "metadata": {},
   "source": [
    "## Copy-pasted Dunning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eac85a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# http://pioneer.chula.ac.th/~awirote/colloc/statmethod1.htm\n",
    "# https://github.com/dhmit/gender_novels/blob/master/gender_novels/analysis/dunning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a7b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunning_total(t1, t2):\n",
    "    \"\"\"Does Dunning log-likelihood on two tables of word counts.\n",
    "    Positive means words in arg 1. Negative means words in arg 2.\n",
    "    The larger the magnitude of the number, the more distinctive that word is in its\n",
    "    respective counter object.\n",
    "    Result is a dict that maps each word to its to results.\n",
    "    Each result dict contains the dunning score.\n",
    "    >>> results['he']\n",
    "    -8.547243830635558\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "\n",
    "    n1 = sum(t1.values())\n",
    "    n2 = sum(t2.values())\n",
    "    \n",
    "    dunning_result = {}  # dictionary where results will be returned\n",
    "    for w in t1:\n",
    "        if w not in t2:\n",
    "            continue\n",
    "        if t1[w] + t2[w] < 10:\n",
    "            continue\n",
    "        Pr_1 = t1[w] / n1\n",
    "        Pr_2 = t2[w] / n2\n",
    "        Pr_12 = (t1[w] + t2[w]) / (n1 + n2)\n",
    "\n",
    "        d = 2 * (t1[w] * math.log(Pr_1 / Pr_12) + t2[w] * math.log(Pr_2 / Pr_12))\n",
    "\n",
    "        if t1[w] * math.log(Pr_1 / Pr_12) < 0:\n",
    "            d = -1 * d\n",
    "        dunning_result[w] = d\n",
    "\n",
    "    return dunning_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7317d1",
   "metadata": {},
   "source": [
    "## Do the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29291d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dunning_total(pcount, scount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40864cce",
   "metadata": {},
   "source": [
    "## Limit to the very most significant, and display them sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645bd24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mr': 401.1,\n",
       " 'aunt': 97.4,\n",
       " 'father': 64.1,\n",
       " 'ball': 41.5,\n",
       " 'william': 41.4,\n",
       " 'mary': 38.9,\n",
       " 'uncle': 34.1,\n",
       " 'mother': -33.8,\n",
       " 'heart': -42.3,\n",
       " 'mrs': -43.4,\n",
       " 'colonel': -46.8,\n",
       " 'body': -56.0,\n",
       " 'thing': -100.9,\n",
       " 'john': -188.0,\n",
       " 'edward': -297.6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 30\n",
    "filtered = {}\n",
    "for word in result:\n",
    "    d = result[word]\n",
    "    if d > THRESHOLD or d < (-1 * THRESHOLD):\n",
    "        filtered[word] = round(d,1)\n",
    "\n",
    "# negative means Sense, positive means Pride\n",
    "\n",
    "filtered_sorted = dict(sorted(filtered.items(), key=lambda item: item[1], reverse=True))\n",
    "filtered_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6872b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
